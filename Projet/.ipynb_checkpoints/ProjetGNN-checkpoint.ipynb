{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c636c29-33b1-47a3-8224-a280137c6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx, train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7824d254-46fa-4077-bd1c-65b1f8926785",
   "metadata": {},
   "source": [
    "# Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf4fa2-08b3-4206-9d6e-02eff6341260",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae830f18-d6c6-4353-a624-5abcede8ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 27094], x=[3363, 5])\n",
      "<class 'torch_geometric.data.data.Data'>\n",
      "\n",
      "Node features shape (x): torch.Size([3363, 5])\n",
      "Edge index shape: torch.Size([2, 27094])\n",
      "Number of nodes: 3363\n",
      "Number of edges: 27094\n",
      "Is directed? False\n",
      "Number of node features: 5\n",
      "\n",
      "First 5 node feature vectors:\n",
      "tensor([[-1.4551e+02, -1.7354e+01,  1.0000e+04,  6.6000e+01,  9.9000e+01],\n",
      "        [-1.4095e+02, -1.8067e+01,  1.0000e+04,  6.6000e+01,  1.0710e+03],\n",
      "        [-1.4960e+02, -1.7550e+01,  2.6357e+04,  6.6000e+01,  2.2070e+03],\n",
      "        [-1.3500e+02, -2.3033e+01,  1.0000e+04,  6.6000e+01,  9.2000e+02],\n",
      "        [-1.4366e+02, -1.6585e+01,  1.0000e+04,  6.6000e+01,  1.7050e+03]])\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml('datasetAirports.graphml')\n",
    "\n",
    "# Important: Clear the graph-level attributes to avoid bugs\n",
    "G.graph = {}\n",
    "\n",
    "#Encoding des variables textuelles\n",
    "country_encoder = LabelEncoder()\n",
    "city_encoder = LabelEncoder()\n",
    "\n",
    "countries = [data.get(\"country\", \"UNK\") for _, data in G.nodes(data=True)]\n",
    "cities = [data.get(\"city_name\", \"UNK\") for _, data in G.nodes(data=True)]\n",
    "\n",
    "# Fit les encoders\n",
    "country_encoder.fit(countries)\n",
    "city_encoder.fit(cities)\n",
    "\n",
    "# Appliquer l'encodage\n",
    "for _, data in G.nodes(data=True):\n",
    "    data[\"country\"] = country_encoder.transform([data.get(\"country\", \"UNK\")])[0]\n",
    "    data[\"city_name\"] = city_encoder.transform([data.get(\"city_name\", \"UNK\")])[0]\n",
    "\n",
    "# On garde des dictoinaires pour faire le lien entre encoding et valeur de base\n",
    "country_to_encoding = {label: int(country_encoder.transform([label])[0]) for label in country_encoder.classes_}\n",
    "encoding_to_country = {v: k for k, v in country_to_encoding.items()}\n",
    "city_to_encoding = {label: int(city_encoder.transform([label])[0]) for label in city_encoder.classes_}\n",
    "encoding_to_city = {v: k for k, v in city_to_encoding.items()}\n",
    "\n",
    "# Convert NetworkX graph to PyTorch Geometric Data object\n",
    "data = from_networkx(G, group_node_attrs=[\"lon\", \"lat\", \"population\", \"country\", \"city_name\"])\n",
    "\n",
    "# Display the converted data\n",
    "print(data)\n",
    "print(type(data))\n",
    "print(f\"\\nNode features shape (x): {data.x.shape}\")\n",
    "print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(\"Is directed?\", nx.is_directed(G))  # False âœ…\n",
    "print(f\"Number of node features: {data.num_node_features}\")\n",
    "\n",
    "# Check the first few node features\n",
    "print(f\"\\nFirst 5 node feature vectors:\\n{data.x[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f06c1-2ba2-47ba-b55a-2cabcbc9b874",
   "metadata": {},
   "source": [
    "## Data Preparation before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11e5c157-260b-4a7e-a16c-1e16922a56f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EDGE SPLIT SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Training edges:\n",
      "  - train_pos_edge_index shape: torch.Size([2, 21676])\n",
      "  - Number of training edges: 21676\n",
      "\n",
      "Test edges (positive - actual edges to predict):\n",
      "  - test_pos_edge_index shape: torch.Size([2, 2709])\n",
      "  - Number of test positive edges: 2709\n",
      "\n",
      "Test edges (negative - non-existent edges):\n",
      "  - test_neg_edge_index shape: torch.Size([2, 2709])\n",
      "  - Number of test negative edges: 2709\n",
      "\n",
      "Node features (unchanged):\n",
      "  - x shape: torch.Size([3363, 5])\n",
      "  - All node features preserved: 3363 nodes, 5 features\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION\n",
      "======================================================================\n",
      "Original edges (directed): 27094\n",
      "Training edges: 21676 (80.0%)\n",
      "Test positive edges: 2709 (10.0%)\n",
      "Test negative edges: 2709\n",
      "\n",
      "======================================================================\n",
      "SAMPLE EDGES\n",
      "======================================================================\n",
      "\n",
      "Sample training edges (first 5):\n",
      "  Edge 1: Node 0 <-> Node 1\n",
      "  Edge 2: Node 0 <-> Node 2\n",
      "  Edge 3: Node 1 <-> Node 0\n",
      "  Edge 4: Node 1 <-> Node 2\n",
      "  Edge 5: Node 1 <-> Node 3\n",
      "\n",
      "Sample test positive edges (first 5):\n",
      "  Edge 1: Node 44 <-> Node 234 (should exist)\n",
      "  Edge 2: Node 175 <-> Node 1594 (should exist)\n",
      "  Edge 3: Node 272 <-> Node 736 (should exist)\n",
      "  Edge 4: Node 127 <-> Node 694 (should exist)\n",
      "  Edge 5: Node 52 <-> Node 93 (should exist)\n",
      "\n",
      "Sample test negative edges (first 5):\n",
      "  Edge 1: Node 2030 <-> Node 2759 (should NOT exist)\n",
      "  Edge 2: Node 185 <-> Node 1691 (should NOT exist)\n",
      "  Edge 3: Node 170 <-> Node 1466 (should NOT exist)\n",
      "  Edge 4: Node 1830 <-> Node 2103 (should NOT exist)\n",
      "  Edge 5: Node 10 <-> Node 2014 (should NOT exist)\n"
     ]
    }
   ],
   "source": [
    "data = train_test_split_edges(data, val_ratio=0.0, test_ratio=0.2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EDGE SPLIT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTraining edges:\")\n",
    "print(f\"  - train_pos_edge_index shape: {data.train_pos_edge_index.shape}\")\n",
    "print(f\"  - Number of training edges: {data.train_pos_edge_index.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTest edges (positive - actual edges to predict):\")\n",
    "print(f\"  - test_pos_edge_index shape: {data.test_pos_edge_index.shape}\")\n",
    "print(f\"  - Number of test positive edges: {data.test_pos_edge_index.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTest edges (negative - non-existent edges):\")\n",
    "print(f\"  - test_neg_edge_index shape: {data.test_neg_edge_index.shape}\")\n",
    "print(f\"  - Number of test negative edges: {data.test_neg_edge_index.shape[1]}\")\n",
    "\n",
    "print(f\"\\nNode features (unchanged):\")\n",
    "print(f\"  - x shape: {data.x.shape}\")\n",
    "print(f\"  - All node features preserved: {data.x.shape[0]} nodes, {data.x.shape[1]} features\")\n",
    "\n",
    "# Verify the split\n",
    "total_original_edges = G.number_of_edges() * 2  # Undirected, so counted twice\n",
    "train_edges = data.train_pos_edge_index.shape[1]\n",
    "test_edges = data.test_pos_edge_index.shape[1]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Original edges (directed): {total_original_edges}\")\n",
    "print(f\"Training edges: {train_edges} ({train_edges/total_original_edges*100:.1f}%)\")\n",
    "print(f\"Test positive edges: {test_edges} ({test_edges/total_original_edges*100:.1f}%)\")\n",
    "print(f\"Test negative edges: {data.test_neg_edge_index.shape[1]}\")\n",
    "\n",
    "# Show sample edges\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE EDGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nSample training edges (first 5):\")\n",
    "for i in range(min(5, data.train_pos_edge_index.shape[1])):\n",
    "    src = data.train_pos_edge_index[0, i].item()\n",
    "    dst = data.train_pos_edge_index[1, i].item()\n",
    "    print(f\"  Edge {i+1}: Node {src} <-> Node {dst}\")\n",
    "\n",
    "print(\"\\nSample test positive edges (first 5):\")\n",
    "for i in range(min(5, data.test_pos_edge_index.shape[1])):\n",
    "    src = data.test_pos_edge_index[0, i].item()\n",
    "    dst = data.test_pos_edge_index[1, i].item()\n",
    "    print(f\"  Edge {i+1}: Node {src} <-> Node {dst} (should exist)\")\n",
    "\n",
    "print(\"\\nSample test negative edges (first 5):\")\n",
    "for i in range(min(5, data.test_neg_edge_index.shape[1])):\n",
    "    src = data.test_neg_edge_index[0, i].item()\n",
    "    dst = data.test_neg_edge_index[1, i].item()\n",
    "    print(f\"  Edge {i+1}: Node {src} <-> Node {dst} (should NOT exist)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a99220-6585-4cc0-abb9-c1075c2da612",
   "metadata": {},
   "source": [
    "## Definition & Initialisation of encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca525bc3-5a78-4082-ba86-08f06bb5cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VGAE MODEL ARCHITECTURE\n",
      "======================================================================\n",
      "\n",
      "Encoder:\n",
      "  Input features: 5\n",
      "  Hidden dimension: 32\n",
      "  Latent dimension: 16\n",
      "\n",
      "Model structure:\n",
      "VGAE(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): GCNConv(5, 32)\n",
      "    (conv_mu): GCNConv(32, 16)\n",
      "    (conv_logstd): GCNConv(32, 16)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "\n",
      "======================================================================\n",
      "ENCODER OUTPUT DIMENSIONS\n",
      "======================================================================\n",
      "Mean (mu) shape: torch.Size([3363, 16]) - [3363 nodes Ã— 16 latent dims]\n",
      "Log std (logstd) shape: torch.Size([3363, 16]) - [3363 nodes Ã— 16 latent dims]\n"
     ]
    }
   ],
   "source": [
    "# Encoder class for VGAE\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "in_channels = data.num_features\n",
    "out_channels = 16\n",
    "\n",
    "encoder = Encoder(in_channels, out_channels)\n",
    "model = VGAE(encoder)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VGAE MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nEncoder:\")\n",
    "print(f\"  Input features: {in_channels}\")\n",
    "print(f\"  Hidden dimension: {2 * out_channels}\")\n",
    "print(f\"  Latent dimension: {out_channels}\")\n",
    "print(f\"\\nModel structure:\")\n",
    "print(model)\n",
    "\n",
    "# Check the encoder output dimensions\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ENCODER OUTPUT DIMENSIONS\")\n",
    "print(\"=\"*70)\n",
    "with torch.no_grad():\n",
    "    mu, logstd = encoder(data.x, data.train_pos_edge_index)\n",
    "    print(f\"Mean (mu) shape: {mu.shape} - [{data.num_nodes} nodes Ã— {out_channels} latent dims]\")\n",
    "    print(f\"Log std (logstd) shape: {logstd.shape} - [{data.num_nodes} nodes Ã— {out_channels} latent dims]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43a9c5-f8e2-44f4-8b77-aaf72f39fd23",
   "metadata": {},
   "source": [
    "## Training - A FAIRE G JUSTE COPIÃ‰ COLLER LE TP SUR CETTE PARTIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52917ed-dea7-4172-a4dc-2bbaaba75438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure model and data are on the correct device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VGAE TRAINING AND EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Training function - uses ONLY training edges\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # IMPORTANT: Encode using ONLY training edges\n",
    "    z = model.encode(data_edge.x, data_edge.train_pos_edge_index)\n",
    "    \n",
    "    # Compute reconstruction loss on training edges only\n",
    "    loss = model.recon_loss(z, data_edge.train_pos_edge_index)\n",
    "    \n",
    "    # Add KL divergence regularization\n",
    "    loss = loss + (1 / data_edge.num_nodes) * model.kl_loss()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "# Testing function - uses training edges for encoding, test edges for evaluation\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # IMPORTANT: Encode using ONLY training edges (not test edges!)\n",
    "        # This ensures we don't leak information from test set\n",
    "        z = model.encode(data_edge.x, data_edge.train_pos_edge_index)\n",
    "        \n",
    "        # Evaluate on test edges\n",
    "        auc, ap = model.test(z, pos_edge_index, neg_edge_index)\n",
    "    \n",
    "    return auc, ap\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTraining Progress:\")\n",
    "print(f\"{'Epoch':<8} {'Loss':<12} {'Test AUC':<12} {'Test AP':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "num_epochs = 200\n",
    "best_auc = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        auc, ap = test(data_edge.test_pos_edge_index, data_edge.test_neg_edge_index)\n",
    "        print(f\"{epoch:<8} {loss:<12.4f} {auc:<12.4f} {ap:<12.4f}\")\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TEST EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Final comprehensive evaluation\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Encode using TRAINING edges only\n",
    "    z = model.encode(data_edge.x, data_edge.train_pos_edge_index)\n",
    "    \n",
    "    # Evaluate on TEST edges\n",
    "    test_auc, test_ap = model.test(z, data_edge.test_pos_edge_index, \n",
    "                                     data_edge.test_neg_edge_index)\n",
    "    \n",
    "    # Get predictions for positive test edges\n",
    "    pos_pred = model.decoder(z, data_edge.test_pos_edge_index, sigmoid=True)\n",
    "    \n",
    "    # Get predictions for negative test edges  \n",
    "    neg_pred = model.decoder(z, data_edge.test_neg_edge_index, sigmoid=True)\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  AUC: {test_auc:.4f}\")\n",
    "print(f\"  AP:  {test_ap:.4f}\")\n",
    "\n",
    "print(f\"\\nPrediction Statistics on Test Set:\")\n",
    "print(f\"  Positive edges (should exist):\")\n",
    "print(f\"    Mean: {pos_pred.mean().item():.4f}\")\n",
    "print(f\"    Std:  {pos_pred.std().item():.4f}\")\n",
    "print(f\"  Negative edges (should NOT exist):\")\n",
    "print(f\"    Mean: {neg_pred.mean().item():.4f}\")\n",
    "print(f\"    Std:  {neg_pred.std().item():.4f}\")\n",
    "\n",
    "# Detailed analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED TEST SET ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine predictions and labels\n",
    "all_preds = torch.cat([pos_pred, neg_pred]).cpu().numpy()\n",
    "all_labels = torch.cat([\n",
    "    torch.ones(pos_pred.shape[0]),\n",
    "    torch.zeros(neg_pred.shape[0])\n",
    "]).numpy()\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "threshold = 0.5\n",
    "binary_preds = (all_preds > threshold).astype(int)\n",
    "\n",
    "precision = precision_score(all_labels, binary_preds)\n",
    "recall = recall_score(all_labels, binary_preds)\n",
    "f1 = f1_score(all_labels, binary_preds)\n",
    "\n",
    "print(f\"\\nWith threshold = {threshold}:\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Count correct predictions\n",
    "correct_pos = (pos_pred > threshold).sum().item()\n",
    "correct_neg = (neg_pred < threshold).sum().item()\n",
    "total_correct = correct_pos + correct_neg\n",
    "total_test = len(pos_pred) + len(neg_pred)\n",
    "\n",
    "print(f\"\\nAccuracy breakdown:\")\n",
    "print(f\"  Positive edges correctly predicted: {correct_pos}/{len(pos_pred)} ({correct_pos/len(pos_pred)*100:.1f}%)\")\n",
    "print(f\"  Negative edges correctly predicted: {correct_neg}/{len(neg_pred)} ({correct_neg/len(neg_pred)*100:.1f}%)\")\n",
    "print(f\"  Overall accuracy: {total_correct}/{total_test} ({total_correct/total_test*100:.1f}%)\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE TEST PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nPositive test edges (first 10):\")\n",
    "print(f\"{'Edge':<15} {'Probability':<12} {'Prediction':<12}\")\n",
    "print(\"-\"*40)\n",
    "for i in range(min(10, len(pos_pred))):\n",
    "    src = data_edge.test_pos_edge_index[0, i].item()\n",
    "    dst = data_edge.test_pos_edge_index[1, i].item()\n",
    "    prob = pos_pred[i].item()\n",
    "    pred_label = \"EXISTS âœ“\" if prob > threshold else \"NO EDGE âœ—\"\n",
    "    print(f\"{src:2d} <-> {dst:2d}      {prob:<12.4f} {pred_label}\")\n",
    "\n",
    "print(\"\\nNegative test edges (first 10):\")\n",
    "print(f\"{'Edge':<15} {'Probability':<12} {'Prediction':<12}\")\n",
    "print(\"-\"*40)\n",
    "for i in range(min(10, len(neg_pred))):\n",
    "    src = data_edge.test_neg_edge_index[0, i].item()\n",
    "    dst = data_edge.test_neg_edge_index[1, i].item()\n",
    "    prob = neg_pred[i].item()\n",
    "    pred_label = \"NO EDGE âœ“\" if prob < threshold else \"EXISTS âœ—\"\n",
    "    print(f\"{src:2d} <-> {dst:2d}      {prob:<12.4f} {pred_label}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY POINTS ABOUT TRAIN/TEST SEPARATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "âœ“ CORRECT: During training, encode with train_pos_edge_index\n",
    "âœ“ CORRECT: During testing, encode with train_pos_edge_index\n",
    "âœ“ CORRECT: Evaluate predictions on test_pos_edge_index and test_neg_edge_index\n",
    "\n",
    "âœ— WRONG: Using test edges during encoding (information leakage!)\n",
    "âœ— WRONG: Evaluating on training edges (overly optimistic results)\n",
    "\n",
    "The model learns node embeddings from training edges only.\n",
    "Test edges are completely hidden during training and encoding.\n",
    "This ensures fair evaluation of link prediction performance.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354eac8-88f7-4239-ba95-c1d200212d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fcd84-7092-4a44-b8d0-94237543c5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a8147-c8ba-493f-9dc9-8967477d5878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be48b5-05ae-4318-9c42-3b615a75b2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
