{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c636c29-33b1-47a3-8224-a280137c6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import from_networkx, train_test_split_edges\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7824d254-46fa-4077-bd1c-65b1f8926785",
   "metadata": {},
   "source": [
    "# Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf4fa2-08b3-4206-9d6e-02eff6341260",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae830f18-d6c6-4353-a624-5abcede8ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph with 3363 nodes and 13547 edges\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml('datasetAirports.graphml')\n",
    "\n",
    "# Important: Clear the graph-level attributes to avoid bugs\n",
    "G.graph = {}\n",
    "print(f\"Loaded graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5b6202-341d-4853-b9c0-cb7d8d9262a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 27094], x=[3363, 5])\n",
      "<class 'torch_geometric.data.data.Data'>\n",
      "\n",
      "Node features shape (x): torch.Size([3363, 5])\n",
      "Edge index shape: torch.Size([2, 27094])\n",
      "Number of nodes: 3363\n",
      "Number of edges: 27094\n",
      "Is directed? False\n",
      "Number of node features: 5\n",
      "\n",
      "First 5 node feature vectors:\n",
      "tensor([[-1.4551e+02, -1.7354e+01,  1.0000e+04,  6.6000e+01,  9.9000e+01],\n",
      "        [-1.4095e+02, -1.8067e+01,  1.0000e+04,  6.6000e+01,  1.0710e+03],\n",
      "        [-1.4960e+02, -1.7550e+01,  2.6357e+04,  6.6000e+01,  2.2070e+03],\n",
      "        [-1.3500e+02, -2.3033e+01,  1.0000e+04,  6.6000e+01,  9.2000e+02],\n",
      "        [-1.4366e+02, -1.6585e+01,  1.0000e+04,  6.6000e+01,  1.7050e+03]])\n"
     ]
    }
   ],
   "source": [
    "#Encoding des variables textuelles\n",
    "country_encoder = LabelEncoder()\n",
    "city_encoder = LabelEncoder()\n",
    "\n",
    "countries = [data.get(\"country\", \"UNK\") for _, data in G.nodes(data=True)]\n",
    "cities = [data.get(\"city_name\", \"UNK\") for _, data in G.nodes(data=True)]\n",
    "\n",
    "# Fit les encoders\n",
    "country_encoder.fit(countries)\n",
    "city_encoder.fit(cities)\n",
    "\n",
    "# Appliquer l'encodage\n",
    "for _, data in G.nodes(data=True):\n",
    "    data[\"country\"] = country_encoder.transform([data.get(\"country\", \"UNK\")])[0]\n",
    "    data[\"city_name\"] = city_encoder.transform([data.get(\"city_name\", \"UNK\")])[0]\n",
    "\n",
    "# On garde des dictoinaires pour faire le lien entre encoding et valeur de base\n",
    "country_to_encoding = {label: int(country_encoder.transform([label])[0]) for label in country_encoder.classes_}\n",
    "encoding_to_country = {v: k for k, v in country_to_encoding.items()}\n",
    "city_to_encoding = {label: int(city_encoder.transform([label])[0]) for label in city_encoder.classes_}\n",
    "encoding_to_city = {v: k for k, v in city_to_encoding.items()}\n",
    "\n",
    "# Convert NetworkX graph to PyTorch Geometric Data object\n",
    "data = from_networkx(G, group_node_attrs=[\"lon\", \"lat\", \"population\", \"country\", \"city_name\"])\n",
    "\n",
    "# Display the converted data\n",
    "print(data)\n",
    "print(type(data))\n",
    "print(f\"\\nNode features shape (x): {data.x.shape}\")\n",
    "print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(\"Is directed?\", nx.is_directed(G))  # False ✅\n",
    "print(f\"Number of node features: {data.num_node_features}\")\n",
    "\n",
    "# Check the first few node features\n",
    "print(f\"\\nFirst 5 node feature vectors:\\n{data.x[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f06c1-2ba2-47ba-b55a-2cabcbc9b874",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ec60135-11a4-4364-abba-acf876dbc125",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'country'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Count airports per country\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m country_counts = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcountry\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Plot top 20 countries with the most airports\u001b[39;00m\n\u001b[32m      5\u001b[39m top_countries = country_counts.head(\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/data/data.py:577\u001b[39m, in \u001b[36mData.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch_geometric/data/storage.py:118\u001b[39m, in \u001b[36mBaseStorage.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'country'"
     ]
    }
   ],
   "source": [
    "# Count airports per country\n",
    "country_counts = data['country'].value_counts()\n",
    "\n",
    "# Plot top 20 countries with the most airports\n",
    "top_countries = country_counts.head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_countries.plot(kind='bar', color='coral', edgecolor='black')\n",
    "plt.title(\"Top 20 Countries by Number of Airports\")\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Number of Airports\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f20041-3d4b-42ae-995e-daa89ec01ac4",
   "metadata": {},
   "source": [
    "## Data Preparation before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e5c157-260b-4a7e-a16c-1e16922a56f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EDGE SPLIT SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Training edges:\n",
      "  - train_pos_edge_index shape: torch.Size([2, 21676])\n",
      "  - Number of training edges: 21676\n",
      "\n",
      "Test edges (positive - actual edges to predict):\n",
      "  - test_pos_edge_index shape: torch.Size([2, 2709])\n",
      "  - Number of test positive edges: 2709\n",
      "\n",
      "Test edges (negative - non-existent edges):\n",
      "  - test_neg_edge_index shape: torch.Size([2, 2709])\n",
      "  - Number of test negative edges: 2709\n",
      "\n",
      "Node features (unchanged):\n",
      "  - x shape: torch.Size([3363, 5])\n",
      "  - All node features preserved: 3363 nodes, 5 features\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION\n",
      "======================================================================\n",
      "Original edges (directed): 27094\n",
      "Training edges: 21676 (80.0%)\n",
      "Test positive edges: 2709 (10.0%)\n",
      "Test negative edges: 2709\n",
      "\n",
      "======================================================================\n",
      "SAMPLE EDGES\n",
      "======================================================================\n",
      "\n",
      "Sample training edges (first 5):\n",
      "  Edge 1: Node 0 <-> Node 1\n",
      "  Edge 2: Node 0 <-> Node 2\n",
      "  Edge 3: Node 1 <-> Node 0\n",
      "  Edge 4: Node 1 <-> Node 2\n",
      "  Edge 5: Node 1 <-> Node 4\n",
      "\n",
      "Sample test positive edges (first 5):\n",
      "  Edge 1: Node 1082 <-> Node 2055 (should exist)\n",
      "  Edge 2: Node 118 <-> Node 665 (should exist)\n",
      "  Edge 3: Node 133 <-> Node 1012 (should exist)\n",
      "  Edge 4: Node 2576 <-> Node 3186 (should exist)\n",
      "  Edge 5: Node 34 <-> Node 54 (should exist)\n",
      "\n",
      "Sample test negative edges (first 5):\n",
      "  Edge 1: Node 1992 <-> Node 2392 (should NOT exist)\n",
      "  Edge 2: Node 747 <-> Node 1503 (should NOT exist)\n",
      "  Edge 3: Node 1853 <-> Node 2496 (should NOT exist)\n",
      "  Edge 4: Node 1403 <-> Node 2529 (should NOT exist)\n",
      "  Edge 5: Node 1887 <-> Node 2311 (should NOT exist)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duybeobn1/miniconda3/envs/tpdeeprl2025/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = train_test_split_edges(data, val_ratio=0.1, test_ratio=0.1)\n",
    "\n",
    "print(f\"Training edges: {data.train_pos_edge_index.size(1)}\")\n",
    "print(f\"Test positive edges: {data.test_pos_edge_index.size(1)}\")\n",
    "print(f\"Test negative edges: {data.test_neg_edge_index.size(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a99220-6585-4cc0-abb9-c1075c2da612",
   "metadata": {},
   "source": [
    "## Definition & Initialisation of encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca525bc3-5a78-4082-ba86-08f06bb5cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VGAE MODEL ARCHITECTURE\n",
      "======================================================================\n",
      "\n",
      "Encoder:\n",
      "  Input features: 5\n",
      "  Hidden dimension: 32\n",
      "  Latent dimension: 16\n",
      "\n",
      "Model structure:\n",
      "VGAE(\n",
      "  (encoder): Encoder(\n",
      "    (conv1): GCNConv(5, 32)\n",
      "    (conv_mu): GCNConv(32, 16)\n",
      "    (conv_logstd): GCNConv(32, 16)\n",
      "  )\n",
      "  (decoder): InnerProductDecoder()\n",
      ")\n",
      "\n",
      "======================================================================\n",
      "ENCODER OUTPUT DIMENSIONS\n",
      "======================================================================\n",
      "Mean (mu) shape: torch.Size([3363, 16]) - [3363 nodes × 16 latent dims]\n",
      "Log std (logstd) shape: torch.Size([3363, 16]) - [3363 nodes × 16 latent dims]\n"
     ]
    }
   ],
   "source": [
    "# Encoder class for VGAE\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
    "\n",
    "in_channels = data.num_features\n",
    "out_channels = 16\n",
    "\n",
    "encoder = Encoder(in_channels, out_channels)\n",
    "model = VGAE(encoder)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VGAE MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nEncoder:\")\n",
    "print(f\"  Input features: {in_channels}\")\n",
    "print(f\"  Hidden dimension: {2 * out_channels}\")\n",
    "print(f\"  Latent dimension: {out_channels}\")\n",
    "print(f\"\\nModel structure:\")\n",
    "print(model)\n",
    "\n",
    "# Check the encoder output dimensions\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"ENCODER OUTPUT DIMENSIONS\")\n",
    "print(\"=\"*70)\n",
    "with torch.no_grad():\n",
    "    mu, logstd = encoder(data.x, data.train_pos_edge_index)\n",
    "    print(f\"Mean (mu) shape: {mu.shape} - [{data.num_nodes} nodes × {out_channels} latent dims]\")\n",
    "    print(f\"Log std (logstd) shape: {logstd.shape} - [{data.num_nodes} nodes × {out_channels} latent dims]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43a9c5-f8e2-44f4-8b77-aaf72f39fd23",
   "metadata": {},
   "source": [
    "## Training - A FAIRE G JUSTE COPIÉ COLLER LE TP SUR CETTE PARTIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52917ed-dea7-4172-a4dc-2bbaaba75438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VGAE TRAINING AND EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Training Progress:\n",
      "Epoch    Loss         Test AUC     Test AP     \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_edge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m best_auc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     57\u001b[0m         auc, ap \u001b[38;5;241m=\u001b[39m test(data_edge\u001b[38;5;241m.\u001b[39mtest_pos_edge_index, data_edge\u001b[38;5;241m.\u001b[39mtest_neg_edge_index)\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# IMPORTANT: Encode using ONLY training edges\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\u001b[43mdata_edge\u001b[49m\u001b[38;5;241m.\u001b[39mx, data_edge\u001b[38;5;241m.\u001b[39mtrain_pos_edge_index)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute reconstruction loss on training edges only\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrecon_loss(z, data_edge\u001b[38;5;241m.\u001b[39mtrain_pos_edge_index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_edge' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure model and data are on the correct device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VGAE TRAINING AND EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Training function - uses ONLY training edges\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # IMPORTANT: Encode using ONLY training edges\n",
    "    z = model.encode(data_edge.x, data_edge.train_pos_edge_index)\n",
    "    \n",
    "    # Compute reconstruction loss on training edges only\n",
    "    loss = model.recon_loss(z, data_edge.train_pos_edge_index)\n",
    "    \n",
    "    # Add KL divergence regularization\n",
    "    loss = loss + (1 / data_edge.num_nodes) * model.kl_loss()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "# Testing function - uses training edges for encoding, test edges for evaluation\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # IMPORTANT: Encode using ONLY training edges (not test edges!)\n",
    "        # This ensures we don't leak information from test set\n",
    "        z = model.encode(data_edge.x, data_edge.train_pos_edge_index)\n",
    "        \n",
    "        # Evaluate on test edges\n",
    "        auc, ap = model.test(z, pos_edge_index, neg_edge_index)\n",
    "    \n",
    "    return auc, ap\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTraining Progress:\")\n",
    "print(f\"{'Epoch':<8} {'Loss':<12} {'Test AUC':<12} {'Test AP':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "num_epochs = 200\n",
    "best_auc = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        auc, ap = test(data_edge.test_pos_edge_index, data_edge.test_neg_edge_index)\n",
    "        print(f\"{epoch:<8} {loss:<12.4f} {auc:<12.4f} {ap:<12.4f}\")\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TEST EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Final comprehensive evaluation\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Encode using TRAINING edges only\n",
    "    z = model.encode(data_edge.x, data_edge.train_pos_edge_index)\n",
    "    \n",
    "    # Evaluate on TEST edges\n",
    "    test_auc, test_ap = model.test(z, data_edge.test_pos_edge_index, \n",
    "                                     data_edge.test_neg_edge_index)\n",
    "    \n",
    "    # Get predictions for positive test edges\n",
    "    pos_pred = model.decoder(z, data_edge.test_pos_edge_index, sigmoid=True)\n",
    "    \n",
    "    # Get predictions for negative test edges  \n",
    "    neg_pred = model.decoder(z, data_edge.test_neg_edge_index, sigmoid=True)\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  AUC: {test_auc:.4f}\")\n",
    "print(f\"  AP:  {test_ap:.4f}\")\n",
    "\n",
    "print(f\"\\nPrediction Statistics on Test Set:\")\n",
    "print(f\"  Positive edges (should exist):\")\n",
    "print(f\"    Mean: {pos_pred.mean().item():.4f}\")\n",
    "print(f\"    Std:  {pos_pred.std().item():.4f}\")\n",
    "print(f\"  Negative edges (should NOT exist):\")\n",
    "print(f\"    Mean: {neg_pred.mean().item():.4f}\")\n",
    "print(f\"    Std:  {neg_pred.std().item():.4f}\")\n",
    "\n",
    "# Detailed analysis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED TEST SET ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine predictions and labels\n",
    "all_preds = torch.cat([pos_pred, neg_pred]).cpu().numpy()\n",
    "all_labels = torch.cat([\n",
    "    torch.ones(pos_pred.shape[0]),\n",
    "    torch.zeros(neg_pred.shape[0])\n",
    "]).numpy()\n",
    "\n",
    "# Calculate additional metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "threshold = 0.5\n",
    "binary_preds = (all_preds > threshold).astype(int)\n",
    "\n",
    "precision = precision_score(all_labels, binary_preds)\n",
    "recall = recall_score(all_labels, binary_preds)\n",
    "f1 = f1_score(all_labels, binary_preds)\n",
    "\n",
    "print(f\"\\nWith threshold = {threshold}:\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Count correct predictions\n",
    "correct_pos = (pos_pred > threshold).sum().item()\n",
    "correct_neg = (neg_pred < threshold).sum().item()\n",
    "total_correct = correct_pos + correct_neg\n",
    "total_test = len(pos_pred) + len(neg_pred)\n",
    "\n",
    "print(f\"\\nAccuracy breakdown:\")\n",
    "print(f\"  Positive edges correctly predicted: {correct_pos}/{len(pos_pred)} ({correct_pos/len(pos_pred)*100:.1f}%)\")\n",
    "print(f\"  Negative edges correctly predicted: {correct_neg}/{len(neg_pred)} ({correct_neg/len(neg_pred)*100:.1f}%)\")\n",
    "print(f\"  Overall accuracy: {total_correct}/{total_test} ({total_correct/total_test*100:.1f}%)\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE TEST PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nPositive test edges (first 10):\")\n",
    "print(f\"{'Edge':<15} {'Probability':<12} {'Prediction':<12}\")\n",
    "print(\"-\"*40)\n",
    "for i in range(min(10, len(pos_pred))):\n",
    "    src = data_edge.test_pos_edge_index[0, i].item()\n",
    "    dst = data_edge.test_pos_edge_index[1, i].item()\n",
    "    prob = pos_pred[i].item()\n",
    "    pred_label = \"EXISTS ✓\" if prob > threshold else \"NO EDGE ✗\"\n",
    "    print(f\"{src:2d} <-> {dst:2d}      {prob:<12.4f} {pred_label}\")\n",
    "\n",
    "print(\"\\nNegative test edges (first 10):\")\n",
    "print(f\"{'Edge':<15} {'Probability':<12} {'Prediction':<12}\")\n",
    "print(\"-\"*40)\n",
    "for i in range(min(10, len(neg_pred))):\n",
    "    src = data_edge.test_neg_edge_index[0, i].item()\n",
    "    dst = data_edge.test_neg_edge_index[1, i].item()\n",
    "    prob = neg_pred[i].item()\n",
    "    pred_label = \"NO EDGE ✓\" if prob < threshold else \"EXISTS ✗\"\n",
    "    print(f\"{src:2d} <-> {dst:2d}      {prob:<12.4f} {pred_label}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY POINTS ABOUT TRAIN/TEST SEPARATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "✓ CORRECT: During training, encode with train_pos_edge_index\n",
    "✓ CORRECT: During testing, encode with train_pos_edge_index\n",
    "✓ CORRECT: Evaluate predictions on test_pos_edge_index and test_neg_edge_index\n",
    "\n",
    "✗ WRONG: Using test edges during encoding (information leakage!)\n",
    "✗ WRONG: Evaluating on training edges (overly optimistic results)\n",
    "\n",
    "The model learns node embeddings from training edges only.\n",
    "Test edges are completely hidden during training and encoding.\n",
    "This ensures fair evaluation of link prediction performance.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpdeeprl2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
